{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1KaBStH_efYTvtsncAs5YfNB_xkNkzDgV","authorship_tag":"ABX9TyP/bSiW0fLYEeG7OVGLnaHv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Intrusion Detection System using Decision Tree Algorithm on KDD Cup 1999 Dataset\n","\n","## Step 1: Import Libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","\n","## Step 2: Load and Preprocess Dataset\n","# Load the dataset (adjust the file path as needed)\n","# Assuming the dataset is in gzipped format and named 'kddcup.data_10_percent.gz'\n","df = pd.read_csv('/content/drive/MyDrive/Intrusion-Detection-System-master/dataset/kddcup.data_10_percent.gz', compression='gzip', header=None)\n","\n","# Display the first few rows of the dataset\n","df.head()\n","\n","# Assign column names based on the KDD Cup 1999 dataset specification\n","column_names = [\n","    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n","    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\",\n","    \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\",\n","    \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n","    \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n","    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n","    \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n","    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n","    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n","    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"\n","]\n","df.columns = column_names\n","\n","# Handle missing values (if any)\n","df = df.dropna()\n","\n","# Encode categorical variables\n","label_encoder = LabelEncoder()\n","categorical_cols = ['protocol_type', 'service', 'flag', 'label']\n","for col in categorical_cols:\n","    df[col] = label_encoder.fit_transform(df[col])\n","\n","# Separate features and target variable\n","X = df.drop('label', axis=1)\n","y = df['label']\n","\n","# Standardize the feature values\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","## Step 3: Split the Dataset\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","## Step 4: Train the Decision Tree Model\n","# Initialize the Decision Tree classifier\n","dt_classifier = DecisionTreeClassifier(random_state=42)\n","\n","# Train the model\n","dt_classifier.fit(X_train, y_train)\n","\n","## Step 5: Evaluate the Model\n","# Predict the labels for the test set\n","y_pred = dt_classifier.predict(X_test)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","\n","# Print evaluation metrics\n","print(f'Accuracy: {accuracy:.2f}')\n","print(f'Precision: {precision:.2f}')\n","print(f'Recall: {recall:.2f}')\n","print(f'F1 Score: {f1:.2f}')\n","\n","# Print classification report\n","unique_classes = np.unique(y_test)\n","target_names = label_encoder.inverse_transform(unique_classes)\n","print(classification_report(y_test, y_pred, target_names=target_names))\n","\n","## Step 6: Visualize the Results\n","# Confusion Matrix\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","# Feature Importance\n","feature_importances = dt_classifier.feature_importances_\n","features = column_names[:-1]\n","importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n","importance_df = importance_df.sort_values(by='Importance', ascending=False)\n","\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x='Importance', y='Feature', data=importance_df)\n","plt.title('Feature Importance')\n","plt.show()\n"],"metadata":{"id":"BwPUDV41R4nD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Intrusion Detection System using Random Forest Algorithm on KDD Cup 1999 Dataset\n","\n","## Step 1: Import Libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","\n","## Step 2: Load and Preprocess Dataset\n","# Load the dataset (adjust the file path as needed)\n","# Assuming the dataset is in gzipped format and named 'kddcup.data_10_percent.gz'\n","df = pd.read_csv('/content/drive/MyDrive/Intrusion-Detection-System-master/dataset/kddcup.data_10_percent.gz', compression='gzip', header=None)\n","\n","# Display the first few rows of the dataset\n","df.head()\n","\n","# Assign column names based on the KDD Cup 1999 dataset specification\n","column_names = [\n","    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n","    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\",\n","    \"logged_in\", \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\",\n","    \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\",\n","    \"is_host_login\", \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\",\n","    \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\",\n","    \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n","    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n","    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n","    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"\n","]\n","df.columns = column_names\n","\n","# Handle missing values (if any)\n","df = df.dropna()\n","\n","# Encode categorical variables\n","label_encoder = LabelEncoder()\n","categorical_cols = ['protocol_type', 'service', 'flag', 'label']\n","for col in categorical_cols:\n","    df[col] = label_encoder.fit_transform(df[col])\n","\n","# Separate features and target variable\n","X = df.drop('label', axis=1)\n","y = df['label']\n","\n","# Standardize the feature values\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","## Step 3: Split the Dataset\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n","\n","## Step 4: Train the Random Forest Model\n","# Initialize the Random Forest classifier\n","rf_classifier = RandomForestClassifier(random_state=42)\n","\n","# Train the model\n","rf_classifier.fit(X_train, y_train)\n","\n","## Step 5: Evaluate the Model\n","# Predict the labels for the test set\n","y_pred = rf_classifier.predict(X_test)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","\n","# Print evaluation metrics\n","print(f'Accuracy: {accuracy:.2f}')\n","print(f'Precision: {precision:.2f}')\n","print(f'Recall: {recall:.2f}')\n","print(f'F1 Score: {f1:.2f}')\n","\n","# Print classification report\n","unique_classes = np.unique(y_test)\n","target_names = label_encoder.inverse_transform(unique_classes)\n","print(classification_report(y_test, y_pred, target_names=target_names))\n","\n","## Step 6: Visualize the Results\n","# Confusion Matrix\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","# Feature Importance\n","feature_importances = rf_classifier.feature_importances_\n","features = column_names[:-1]\n","importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n","importance_df = importance_df.sort_values(by='Importance', ascending=False)\n","\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x='Importance', y='Feature', data=importance_df)\n","plt.title('Feature Importance')\n","plt.show()\n"],"metadata":{"id":"VVr7IMlWUmvU"},"execution_count":null,"outputs":[]}]}